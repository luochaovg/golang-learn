##### UDP是否有粘包问题
- [参考链接](https://www.cnblogs.com/111testing/p/12810253.html)
```text
UDP 是没有沾包问题的

TCP在建立连接时有三次握手的过程，这样就保证的连接的有效性。发包时发包完成也有反馈（对方接收完成有标记），
所以tcp不存在丢包乱序的问题。但是发包过于频繁时会出现粘包的问题。

UDP建立连接并没有三次握手的过程，而且发送数据只是负责发送，不会有发送成功的反馈，所以当数据量大会被切分为多个小数据发包时会出现丢包现象。

Q：UDP会不会产生粘包问题呢？
TCP为了保证可靠传输并减少额外的开销（每次发包都要验证），采用了基于流的传输，基于流的传输不认为消息是一条一条的，
是无保护消息边界的（保护消息边界：指传输协议把数据当做一条独立的消息在网上传输，接收端一次只能接受一条独立的消息）。
UDP则是面向消息传输的，是有保护消息边界的，接收方一次只接受一条独立的信息，所以不存在粘包问题。

举个例子：有三个数据包，大小分别为2k、4k、6k，如果采用UDP发送的话，不管接受方的接收缓存有多大，我们必须要进行至少三次以上的发送才能把数据包发送完，
但是使用TCP协议发送的话，我们只需要接受方的接收缓存有12k的大小，就可以一次把这3个数据包全部发送完毕。
```

##### Mysql 主从延迟问题，怎么发现又怎么解决 （重要： 理解半同步复制）
- [参考链接](https://blog.csdn.net/hao_yunfeng/article/details/82392261)
```text

mysql数据库从库同步的延迟问题：
在服务器上执行show slave satus;可以看到很多同步的参数

MySql数据库从库同步的延迟解决方案：
1)、架构方面
1.业务的持久化层的实现采用分库架构，mysql服务可平行扩展，分散压力。
2.单个库读写分离，一主多从，主写从读，分散压力。这样从库压力比主库高，保护主库。
3.服务的基础架构在业务和mysql之间加入memcache或者redis的cache层。降低mysql的读压力。
4.不同业务的mysql物理上放在不同机器，分散压力。
5.使用比主库更好的硬件设备作为slave总结，mysql压力小，延迟自然会变小。

2)、硬件方面
1.采用好服务器，比如4u比2u性能明显好，2u比1u性能明显好。
2.存储用ssd或者盘阵或者san，提升随机写的性能。
3.主从间保证处在同一个交换机下面，并且是万兆环境。
总结，硬件强劲，延迟自然会变小。一句话，缩小延迟的解决方案就是花钱和花时间。

3)、mysql主从同步加速
1、sync_binlog在slave端设置为0
2、–logs-slave-updates 从服务器从主服务器接收到的更新不记入它的二进制日志。
3、直接禁用slave端的binlog
4、slave端，如果使用的存储引擎是innodb，innodb_flush_log_at_trx_commit =2
4)、从文件系统本身属性角度优化 


MySql数据库从库同步其他问题及解决方案：
1)、mysql主从复制存在的问题：  ● 主库宕机后，数据可能丢失  ● 从库只有一个sql Thread，主库写压力大，复制很可能延时
2)、解决方法：  ● 半同步复制---解决数据丢失的问题  ● 并行复制----解决从库复制延迟的问题
3)、半同步复制mysql semi-sync（半同步复制）
```

##### Redis 分布式锁 sentx 超时过期但是业务还没有完成， 锁释放了，怎么处理 (重要)
- [参考链接](https://developer.51cto.com/art/202108/679902.htm)
```text
我们使用了redis的分布式锁。具体做法是后端接收到请求后加入一个分布式锁，如果加锁成功，就执行业务，如果加锁失败就等待锁或者拒绝请求。业务执行完成后释放锁。

面试官:你们系统是怎么实现分布式锁的?
我:我们使用了redis的分布式锁。具体做法是后端接收到请求后加入一个分布式锁，如果加锁成功，就执行业务，如果加锁失败就等待锁或者拒绝请求。业务执行完成后释放锁。

面试官:能说一下具体使用的命令吗?
我:我们使用的是SETNX命令，具体如下：
    SETNX KEY_NAME VALUE # 设置成功返回1，设置失败返回0。如下图，客户端1加锁成功，客户端2获取锁失败： 

面试官:这样设置会不会有问题呢?如果加锁成功的客户端挂了怎么办?
我：比如上图中的客户端1挂了，这个锁就不能释放了。可以设置一个过期时间，命令如下：
    SET key value [EX seconds] [PX milliseconds] NX 

面试官:设置了过期时间，如果业务还没有执行完成，但是redis锁过期了，怎么办?
我：需要对锁进行续约。
面试官：能说一下具体怎么操作吗?
我：设置锁成功后，启动一个watchdog，每隔一段时间(比如10s)为当前分布式锁续约，也就是每隔10s重新设置当前key的超时时间。命令如下：
    EXPIRE <key> <seconds>
 
面试官：watchdog怎么实现呢?
我：当客户端加锁成功后，可以启动一个定时任务，每隔10s(最好支持配置)来检测业务是否处理完成，检测的依据就是判断分布式锁的key是否还存在，如果存在，就进行续约。
面试官：如果当前线程已经处理完，这个key是被其他客户端写入的呢?
我：可以为每个客户端指定一个clientID，在VALUE中增加一个clientID的前缀，这样在续锁的时候，可以判断当前分布式锁的value前缀来确定是不是当前客户端的，如果是再续锁，否则不做处理。

面试官:你们的续锁功能是自己实现的吗?
我:我们用的redisson的分布式锁方案，使用redisson获取分布式锁非常简单
    RLock lock = redisson.getLock("client-lock"); 
    lock.lock(); 
    try { 
        //处理业务 
    } catch (Exception e) { 
        //处理异常 
    } finally { 
        lock.unlock(); 
    } 

具体原理是：如果客户端1加锁成功，这个分布式锁超时时间默认是30秒(可以通过Config.lockWatchdogTimeout来修改)。加锁成功后，就会启动一个watchdog，watchdog是一个后台线程，会每隔10秒检查一下客户端1是否还持有锁key，如果是，就延长锁key的生存时间，延长操作就是再次把锁key的超时时间设置成30s。



```


##### TCP 四次挥手， 服务端发送FIN标示后的状态 (复现TCP四次挥手 )
- [参考](https://github.com/luochaovg/golang-learn/blob/master/mianshi/study/01.md)


##### Kafka 消费者丢失处理方法 （重点）
- [参考](https://www.jianshu.com/p/f47c36de8ee4)
```text
consumer端是如何保证数据不丢失的
在consumer消费阶段，对offset的处理，关系到是否丢失数据，是否重复消费数据，因此，我们把处理好offset就可以做到exactly-once && at-least-once(只消费一次)数据。

当enable.auto.commit=true时
表示由kafka的consumer端自动提交offset,当你在pull(拉取)30条数据，
在处理到第20条时自动提交了offset,但是在处理21条的时候出现了异常，
当你再次pull数据时，由于之前是自动提交的offset，所以是从30条之后开始拉取数据，
这也就意味着21-30条的数据发生了丢失。

当enable.auto.commit=false时
由于上面的情况可知自动提交offset时，如果处理数据失败就会发生数据丢失的情况。那我们设置成手动提交。
当设置成false时，由于是手动提交的，可以处理一条提交一条，也可以处理一批，提交一批，
由于consumer在消费数据时是按一个batch来的，当pull了30条数据时，如果我们处理一条，
提交一个offset，这样会严重影响消费的能力，那就需要我们来按一批来处理，或者设置一个累加器，处理一条加1，
如果在处理数据时发生了异常，那就把当前处理失败的offset进行提交(放在finally代码块中)注意一定要确保offset的正确性，
当下次再次消费的时候就可以从提交的offset处进行再次消费。


```
##### 数据库主键ID, 生成方法， 雪花算法出现了相同时怎么解决， (bitmap)

##### 微服务熔断
- [参考1](https://cloud.tencent.com/developer/article/1805170)
- [参考2.重要](https://www.pdai.tech/md/arch/arch-y-reduce.html)
```text
熔断
熔断模式：这种模式主要是参考电路熔断，如果一条线路电压过高，保险丝会熔断，防止火灾。
放到我们的系统中，如果某个目标服务调用慢或者有大量超时，此时，熔断该服务的调用，
对于后续调用请求，不在继续调用目标服务，直接返回，快速释放资源。
如果目标服务情况好转则恢复调用。

定义里面有几个量化的地方

目标服务调用慢或者超时：开启熔断的阀值量化
可以通过两个维度：时间与请求数
    时间 多长时间内的超时请求达到多少，触发熔断
    请求数 从服务启动，超时请求数达到多少，触发
这两个维度都需要记录超时请求数和统计总请求数

情况好转，恢复调用
如何量化情况好转：多长时间之后超时请求数低于多少关闭熔断

```